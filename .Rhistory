X = c(108, 124, 124, 106, 115, 138, 163, 159, 134, 139)
t.test(X, mu = 120, alternative = "one.sided")
t.test(X, mu = 120, alternative = "greater")
confint(X, level=0.99)
conf.int(X, level=0.99)
confint(X, level=0.99)
t.test(X, mu = 120, alternative = "greater", conf.level = 0.99)
confint(X, conf.level = 0.99)
confint(X)
t.test(X, mu = 120, conf.level = 0.99)
t.test(type1, type2, var.equal = TRUE)
type1 = c(65, 81, 57, 66, 82, 82, 67, 59, 75, 70)
type2 = c(64, 71, 83, 59, 65, 56, 69, 74, 82, 79)
t.test(type1, type2, var.equal = TRUE)
t.test(type1, type2, alternative = "two.sided", var.equal = FALSE)
t.test(type1, type2, alternative = "two.sided", var.equal = TRUE)
sd_pooled(type1, type2)
s1 <- sd(type1)
s2 <- sd(type2)
#find sample size of each sample
n1 <- length(type1)
n2 <- length(type2)
#calculate pooled standard deviation
pooled <- sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1+n1-2))
#view pooled standard deviation
pooled
qqnorm(type1,
ylab="percent",
xlab="data",
main="normal probability plot of type 1")
qqnorm(type1,
ylab="percent",
xlab="data",
main="normal probability plot of type 1")
qqline(type1)
probplot(type1)
qqnorm(type1,
ylab="Standardized Residuals",
xlab="data",
main="normal probability plot of type 1")
qqline(type1)
qqnorm(type2,
ylab="Standardized Residuals",
xlab="data",
main="normal probability plot of type 1")
qqline(type2)
qqnorm(type2,
ylab="Standardized Residuals",
xlab="scores",
main="normal probability plot of type 1")
qqline(type2)
qqnorm(type1,
ylab="Standardized Residuals",
xlab="scores",
main="normal probability plot of type 1")
qqline(type1)
qqnorm(type2,
ylab="Standardized Residuals",
xlab="scores",
main="normal probability plot of type 1")
qqline(type2)
qqnorm(type2,
ylab="Standardized Residuals",
xlab="scores",
main="normal probability plot of type 2")
qqline(type2)
Karlsruhe=c(1.186, 1.151, 1.322, 1.339, 1.200, 1.402, 1.365, 1.537, 1.559)
Lehigh=c(1.061, 0.992, 1.063, 1.062, 1.065, 1.178, 1.037, 1.086, 1.052)
t.test(Karlsruhe, Lehigh, paired = TRUE, alternative = "two.sided")
install.packages("nortest")
library(nortest)
ad.test(Karlsruhe)
qqnorm(Karlsruhe)
qqline(Karlsruhe, col = "red")
ad.test(Lehigh)
qqnorm(Lehigh)
qqline(Lehigh, col = "red")
ratio = Karlsruhe[:]/Lehigh[:]
ratio = c(1.186/1.061, 1.151/0.992, 1.322/1.063, 1.339/1.062, 1.200/1.065, 1.402/1.178, 1.365/1.037, 1.537/1.086, 1.559/1.052)
ad.test(ratio)
diff = c(0.125, 0.159, 0.259, 0.277, 0.135, 0.224, 0.328, 0.451, 0.507)
ad.test(diff)
plot(diff)
qqnorm(diff)
qqline(diff, col = "red")
x = rnorm(100)
e = rnorm(100)
y = 3*x-1+e
fit = lm(y~x)
summary(fit)
anova(fit)
x1 = seq(20:50,1)
x1 = seq(20:50)
x1
x1 = seq(20,50)
x1
yhat = 108 + 0.2*x1
yhat
plot(x1,yhat)
yhat2 = 101 + 2.15*x1
yhat2
data = data.frame(x1,yhat1,yhat2)
yhat1 = 108 + 0.2*x1
yhat1
data = data.frame(x1,yhat1,yhat2)
data
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
ggplot(data)+geom_jitter(aes(x1,yhat1),colour="red")+geom_smooth(aes(x1,yhat1,col="red"
),method="lm",se=FALSE)+geom_jitter(aes(x1,yhat2),colour="green")+geom_smooth(aes(x2,yhat2,col="green"),metho
d="lm",se=FALSE)
ggplot(data)+geom_jitter(aes(x1,yhat1),colour="red")+geom_smooth(aes(x1,yhat1,col="red"
),method="lm",se=FALSE)+geom_jitter(aes(x1,yhat2),colour="green")+geom_smooth(aes(x2,yhat2,col="green"),method="lm",se=FALSE)
ggplot(data)+geom_jitter(aes(x1,yhat1),colour="red")+geom_smooth(aes(x1,yhat1,col="red"
),method="lm",se=FALSE)+geom_jitter(aes(x1,yhat2),colour="green")+geom_smooth(aes(x1,yhat2,col="green"),method="lm",se=FALSE)
yhat11 = 132 + 0.2*x1
yhat11
data = data.frame(x1,yhat1,yhat11)
data
ggplot(data)+geom_jitter(aes(x1,yhat1),colour="red")+geom_smooth(aes(x1,yhat1,col="red"
),method="lm",se=FALSE)+geom_jitter(aes(x1,yhat11),colour="green")+geom_smooth(aes(x1,yhat11,col="green"),method="lm",se=FALSE)
yhat2 = 101 + 2.15*x1
yhat2
yhat22 = 119 + 8.15*x1
yhat22
ggplot(data)+geom_jitter(aes(x1,yhat2),colour="red")+geom_smooth(aes(x1,yhat2,col="red"
),method="lm",se=FALSE)+geom_jitter(aes(x1,yhat22),colour="green")+geom_smooth(aes(x1,yhat22,col="green"),method="lm",se=FALSE)
y = c(1+rnorm(10),3+rnorm(10),-2+rnorm(10))
x1=c(rep(1,10),rep(0,20))
x2=c(rep(0,10),rep(1,10),rep(0,10))
x3=c(rep(0,10),rep(0,10),rep(1,10))
fit=lm(y~x1+x2+x3-1)
summary(fit)
fit1=lm(y~x1+x2+x3)
summary(fit1)
x1=rnorm(20,2,1)
x2=rnorm(20,3,4)
e=rnorm(20,0,4)
Y=7*x1-3*x2+e
fit1=lm(Y~x1)
fit2=lm(Y~x2)
summary(fit1)
fit=lm(Y~x1+x2)
summary(fit)
anova(fit1,fit)
qt(0.975,128)
data(table.b1)
x = c(1, 1.7, 1.25, 1.20, 1.45, 1.85, 1.60, 1.50, 1.95, 2)
x2 = x^2
corr(x,x2)
cor(x,x2)
x = c(4, 4, 4, 5, 5, 6, 6.5, 6.5, 6.75, 7, 7.10, 7.30)
y = c(24.6, 24.71, 23.9, 39.50, 39.60, 57.12, 67.11, 67.24, 67.15, 77.87, 80.11, 84.67)
library(nlme)
plot(y~x,lwd=3)
fit.1=lm(y~x)
fit.1
plot(y~x,lwd=3)
abline(fit.1,lwd=3)
new=data.frame(x=c(1:100)/10)
lines(new[,1],predict(fit.2,new),lwd=3,col="blue")
fit.2=lm(y~x+I(x^2))
plot(y~x,lwd=3)
abline(fit.1,lwd=3)
new=data.frame(x=c(1:100)/10)
lines(new[,1],predict(fit.2,new),lwd=3,col="blue")
fit.2
summary(fit.2)
fit.1
summary(fit.1)
fit.2=lm(y~x+I(x^2))
summary(fit.2)
anova(fit.1,fit.2)
x = c(4, 4, 4, 5, 5, 6, 6.5, 6.5, 6.75, 7, 7.10, 7.30)
y = c(24.6, 24.71, 23.9, 39.50, 39.60, 57.12, 67.11, 67.24, 67.15, 77.87, 80.11, 84.67)
library(nlme)
plot(y~x,lwd=3)
fit.1=lm(y~x)
fit.1
summary(fit.1)
fit.2=lm(y~x+I(x^2))
plot(y~x,lwd=3)
abline(fit.1,lwd=3)
new=data.frame(x=c(1:100)/10)
lines(new[,1],predict(fit.2,new),lwd=3,col="blue")
fit.2
summary(fit.2)
anova(fit.1,fit.2)
library(alr3)
install.packages(alr3)
install.packages("alr3")
library(alr3)
library(alr3)
install.packages("C:/Users/mkhalilzadeh1/Downloads/alr3_1.0.0.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/mkhalilzadeh1/Downloads/alr3_2.0.8.tar.gz", repos = NULL, type = "source")
library(alr3)
install.packages("C:/Users/mkhalilzadeh1/Downloads/alr3_2.0.7.tar.gz", repos = NULL, type = "source")
remotes::install_github("cran/alr3")
("cran/alr3")
install_github("cran/alr3")
x1 = c(rep(0,10),rep(1,10),rep(2,10))
x2 = c(rep(0,15),rep(1,15))
y = 1+x1*5-x2*2+3*x1*x2+rnorm(30)
X1 = as.factor(x1)
X2 = as.factor(x2)
fit = lm(y~X1*X2, contrasts = list(X1="contr.sum",X2="contr.sum"))
summary(fit)
x1 = c(rep(0,10),rep(1,10),rep(2,10))
x2 = c(rep(0,5),rep(1,5),rep(0,5),rep(1,5),rep(0,5),rep(1,5))
y = 1+x1*5-x2*2+3*x1*x2+rnorm(30)
X1 = as.factor(x1)
X2 = as.factor(x2)
fit = lm(y~X1*X2, contrasts = list(X1="contr.sum",X2="contr.sum"))
summary(fit)
fit1=lm(y~X1*X2-1)
fit1
x1 = c(rep(0,10),rep(1,10),rep(2,10))
x2 = c(rep(0,5),rep(1,5),rep(0,5),rep(1,5),rep(0,5),rep(1,5))
y = 1+x1*5-x2*2+3*x1*x2+rnorm(30)
X1 = as.factor(x1)
X2 = as.factor(x2)
fit = lm(y~X1*X2, contrasts = list(X1="contr.sum",X2="contr.sum"))
summary(fit)
fit1=lm(y~X1*X2-1)
fit1
fit1=lm(y~X1*X2-1)
fit1
data()
exp(0.3453)
x=rnorm(100,4,2)
z=1+7*x+rnorm(100)
y=z>0
y
y=z>4
y
fit.glm(y~x, family=binomial)
x=rnorm(100,4,2)
z=1+7*x+rnorm(100)
y=(z>16)*1
fit=glm(y~x, family=binomial)
summary(fit)
x=c(rep(1,5),rep(3,7),rep(0,3))
y=9-3*x+rnorm(15)
X=as.factor(x)
fit=lm(y~X-1)
fit
X = model.matrix(fit)[,-1]  # don't include intercept
print(kappa(X, exact=T))
k = model.matrix(fit)[,-1]
print(kappa(X, exact=T))
k = model.matrix(fit)[,-1]
print(kappa(k, exact=T))
x<-predict(fit,newdata=test,type="rsse")
getwd()
setwd("C:/Users/mkhalilzadeh1/Desktop/Fall 2022/Linear Statistical Analysis/Projects")
getwd()
churn <- read.csv("Customer Churn.csv", header = TRUE)
head(churn)
str(churn)
sapply(churn, function(x) sum(is.na(x)))
churn <- churn[complete.cases(churn), ]
churn
churn$customerID <- NULL
head(churn)
churn <- churn[complete.cases(churn), ]
head(churn)
library(psych)
describe(churn)
numeric.var <- sapply(churn, is.numeric)
corr.matrix <- cor(churn[,numeric.var])
corr.matrix
churn$TotalCharges <- NULL
library(plyr)
churn$Churn <- as.factor(mapvalues(churn$Churn,
from=c("No","Yes"),
to=c("0", "1")))
churn$OnlineSecurity <- as.factor(mapvalues(churn$OnlineSecurity,
from =c("No internet service"),to=c("No")))
churn$OnlineBackup <- as.factor(mapvalues(churn$OnlineBackup,
from =c("No internet service"),to=c("No")))
churn$DeviceProtection <- as.factor(mapvalues(churn$DeviceProtection,
from =c("No internet service"),to=c("No")))
churn$TechSupport <- as.factor(mapvalues(churn$TechSupport,
from =c("No internet service"),to=c("No")))
churn$StreamingTV <- as.factor(mapvalues(churn$StreamingTV,
from =c("No internet service"),to=c("No")))
churn$StreamingMovies <- as.factor(mapvalues(churn$StreamingMovies,
from =c("No internet service"),to=c("No")))
churn$MultipleLines <- as.factor(mapvalues(churn$MultipleLines,
from =c("No phone service"),to=c("No")))
churn$SeniorCitizen <- as.factor(mapvalues(churn$SeniorCitizen,
from=c("0","1"),
to=c("No", "Yes")))
str(churn)
null=glm(Churn~1,data=churn, family="binomial")
full=glm(Churn~.,data=churn, family="binomial")
step(null, scope=list(lower=null, upper=full),
direction="forward")
fit.1<-glm(Churn~Contract + InternetService + tenure + PaymentMethod +
MultipleLines + PaperlessBilling + OnlineSecurity + StreamingMovies +
TechSupport + StreamingTV + SeniorCitizen + Dependents +
OnlineBackup,data=churn,family="binomial")
summary(fit.1)
anova(fit.1, test="Chisq")
cooks.distance<-cooks.distance(fit.1)
which(cooks.distance>1)
library(ResourceSelection)
hoslem.test(fit.1$y,fitted(fit.1),g=10)
library(car)
vif(fit.1)
library(pscl)
pR2(fit.1)
library(effects)
plot(allEffects(fit.1))
library(caret)
Churndat<- createDataPartition(churn$Churn,p=0.7,list=FALSE)
set.seed(2022)
train<- churn[Churndat,]
test<- churn[-Churndat,]
fit <- glm(Churn ~ Contract + InternetService + tenure + PaymentMethod +
PaperlessBilling + OnlineSecurity + StreamingMovies + TechSupport +
StreamingTV + PhoneService + MultipleLines + SeniorCitizen +
Dependents + OnlineBackup,family=binomial(link="logit"),data=train)
print(summary(fit))
anova(fit, test="Chisq")
test$Churn <- as.character(test$Churn)
test$Churn[test$Churn=="No"] <- "0"
test$Churn[test$Churn=="Yes"] <- "1"
pred <- predict(fit,newdata=test,type='response')
pred <- ifelse(pred > 0.5,1,0)
misClasificError <- mean(pred != test$Churn)
print(paste('Logistic Regression Accuracy',1-misClasificError))
print("Confusion Matrix for Logistic Regression");
table(test$Churn, pred > 0.5)
library(MASS)
exp(cbind(OR=coef(fit), confint(fit)))
varImp(fit)
x<-predict(fit,newdata=test,type="response")
xr<-prediction(x,test$Churn)
library(ROCR)
xr<-prediction(x,test$Churn)
perform<-performance(xr,measure="tpr",x.measure="fpr")
plot(perform)
auc<-performance(xr,measure="auc")
auc<-auc@y.values[[1]]
auc
getwd()
churn <- read.csv("Customer Churn.csv", header = TRUE)
head(churn)
str(churn)
sapply(churn, function(x) sum(is.na(x)))
churn <- churn[complete.cases(churn), ]
churn
churn$customerID <- NULL
head(churn)
churn <- churn[complete.cases(churn), ]
describe(churn)
numeric.var <- sapply(churn, is.numeric)
corr.matrix <- cor(churn[,numeric.var])
corr.matrix
churn$TotalCharges <- NULL
library(plyr)
churn$Churn <- as.factor(mapvalues(churn$Churn,
from=c("No","Yes"),
to=c("0", "1")))
churn$OnlineSecurity <- as.factor(mapvalues(churn$OnlineSecurity,
from =c("No internet service"),to=c("No")))
churn$OnlineBackup <- as.factor(mapvalues(churn$OnlineBackup,
from =c("No internet service"),to=c("No")))
churn$DeviceProtection <- as.factor(mapvalues(churn$DeviceProtection,
from =c("No internet service"),to=c("No")))
churn$TechSupport <- as.factor(mapvalues(churn$TechSupport,
from =c("No internet service"),to=c("No")))
churn$StreamingTV <- as.factor(mapvalues(churn$StreamingTV,
from =c("No internet service"),to=c("No")))
churn$StreamingMovies <- as.factor(mapvalues(churn$StreamingMovies,
from =c("No internet service"),to=c("No")))
churn$MultipleLines <- as.factor(mapvalues(churn$MultipleLines,
from =c("No phone service"),to=c("No")))
churn$SeniorCitizen <- as.factor(mapvalues(churn$SeniorCitizen,
from=c("0","1"),
to=c("No", "Yes")))
str(churn)
null=glm(Churn~1,data=churn, family="binomial")
full=glm(Churn~.,data=churn, family="binomial")
step(null, scope=list(lower=null, upper=full),
direction="forward")
fit.1<-glm(Churn~Contract + InternetService + tenure + PaymentMethod +
MultipleLines + PaperlessBilling + OnlineSecurity + StreamingMovies +
TechSupport + StreamingTV + SeniorCitizen + Dependents +
OnlineBackup,data=churn,family="binomial")
summary(fit.1)
anova(fit.1, test="Chisq")
cooks.distance<-cooks.distance(fit.1)
which(cooks.distance>1)
library(ResourceSelection)
hoslem.test(fit.1$y,fitted(fit.1),g=10)
vif(fit.1)
library(pscl)
pR2(fit.1)
library(caret)
Churndat<- createDataPartition(churn$Churn,p=0.7,list=FALSE)
set.seed(2022)
train<- churn[Churndat,]
test<- churn[-Churndat,]
fit <- glm(Churn ~ Contract + InternetService + tenure + PaymentMethod +
PaperlessBilling + OnlineSecurity + StreamingMovies + TechSupport +
StreamingTV + PhoneService + MultipleLines + SeniorCitizen +
Dependents + OnlineBackup,family=binomial(link="logit"),data=train)
print(summary(fit))
anova(fit, test="Chisq")
test$Churn <- as.character(test$Churn)
#test$Churn[test$Churn=="No"] <- "0"
#test$Churn[test$Churn=="Yes"] <- "1"
pred <- predict(fit,newdata=test,type='response')
pred <- ifelse(pred > 0.5,1,0)
misClasificError <- mean(pred != test$Churn)
print(paste('Logistic Regression Accuracy',1-misClasificError))
print("Confusion Matrix for Logistic Regression");
table(test$Churn, pred > 0.5)
library(MASS)
exp(cbind(OR=coef(fit), confint(fit)))
varImp(fit)
library(ROCR)
x<-predict(fit,newdata=test,type="response")
xr<-prediction(x,test$Churn)
perform<-performance(xr,measure="tpr",x.measure="fpr")
plot(perform)
auc<-performance(xr,measure="auc")
auc<-auc@y.values[[1]]
auc
